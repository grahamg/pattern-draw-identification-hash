{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60833340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the pattern image\n",
    "pattern_image = tf.io.read_file('pattern.png')\n",
    "\n",
    "# Decode the image and convert it to grayscale\n",
    "pattern_image = tf.image.decode_jpeg(pattern_image, channels=1)\n",
    "\n",
    "# Resize the image to a uniform size\n",
    "pattern_image = tf.image.resize(pattern_image, (224, 224))\n",
    "\n",
    "# Normalize the image\n",
    "pattern_image = pattern_image / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06d6b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the pattern images\n",
    "num_samples=3\n",
    "pattern_labels = [2, 2, 2, 2]\n",
    "pattern_images = []\n",
    "for i in range(num_samples):\n",
    "  pattern_image = tf.io.read_file(f'pattern_{i}.png')\n",
    "  pattern_image = tf.image.decode_jpeg(pattern_image, channels=1)\n",
    "  pattern_image = tf.image.resize(pattern_image, (224, 224))\n",
    "  pattern_image = pattern_image / 255.0\n",
    "  pattern_images.append(pattern_image)\n",
    "\n",
    "# Convert the pattern images to a numpy array\n",
    "pattern_images = np.array(pattern_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "970eb0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training data and labels\n",
    "x_train = np.zeros((num_samples, 224, 224, 1))\n",
    "y_train = np.zeros(num_samples, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e63cd9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_samples):\n",
    "  x_train[i,:,:,:] = pattern_images[i]\n",
    "  y_train[i] = pattern_labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8a34489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 831ms/step - loss: 2.4144 - accuracy: 0.0000e+00 - val_loss: 2.2477 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 5.5631e-07 - accuracy: 1.0000 - val_loss: 2.1548 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 2.0625 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9843 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.9263 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb61988e510>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "x_val = np.zeros((num_samples, 224, 224, 1))\n",
    "y_val = np.zeros(num_samples, dtype=np.int32)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc136f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 224, 224, 1), dtype=tf.float32, name='conv2d_10_input'), name='conv2d_10_input', description=\"created by layer 'conv2d_10_input'\"), but it was called on an input with incompatible shape (32, 224, 1, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/gg/Desktop/pattern-draw-identification-hash/env/lib/python3.7/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/gg/Desktop/pattern-draw-identification-hash/env/lib/python3.7/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/gg/Desktop/pattern-draw-identification-hash/env/lib/python3.7/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/gg/Desktop/pattern-draw-identification-hash/env/lib/python3.7/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/Users/gg/Desktop/pattern-draw-identification-hash/env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer 'conv2d_10' (type Conv2D).\n    \n    Negative dimension size caused by subtracting 3 from 1 for '{{node sequential_5/conv2d_10/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential_5/ExpandDims, sequential_5/conv2d_10/Conv2D/ReadVariableOp)' with input shapes: [32,224,1,1], [3,3,1,32].\n    \n    Call arguments received by layer 'conv2d_10' (type Conv2D):\n      • inputs=tf.Tensor(shape=(32, 224, 1, 1), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d_/d_s1x4gd0bs2cy11fm4rbcsm0000gn/T/ipykernel_25993/686073930.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Pass the pattern image through the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Use the model output as the hash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/pattern-draw-identification-hash/env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/pattern-draw-identification-hash/env/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/gg/Desktop/pattern-draw-identification-hash/env/lib/python3.7/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/gg/Desktop/pattern-draw-identification-hash/env/lib/python3.7/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/gg/Desktop/pattern-draw-identification-hash/env/lib/python3.7/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/gg/Desktop/pattern-draw-identification-hash/env/lib/python3.7/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/Users/gg/Desktop/pattern-draw-identification-hash/env/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer 'conv2d_10' (type Conv2D).\n    \n    Negative dimension size caused by subtracting 3 from 1 for '{{node sequential_5/conv2d_10/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential_5/ExpandDims, sequential_5/conv2d_10/Conv2D/ReadVariableOp)' with input shapes: [32,224,1,1], [3,3,1,32].\n    \n    Call arguments received by layer 'conv2d_10' (type Conv2D):\n      • inputs=tf.Tensor(shape=(32, 224, 1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "# Pass the pattern image through the model\n",
    "prediction = model.predict(pattern_image)\n",
    "\n",
    "# Use the model output as the hash\n",
    "hash = hashlib.sha256(prediction).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d4321d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
